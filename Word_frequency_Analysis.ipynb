{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPAGmwfdBebSmCU/Qm2xpXT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Shreyashi Mukhopadhyay"],"metadata":{"id":"HR-QX31Q8V0k"}},{"cell_type":"markdown","source":["## Problem 1:\n","\n","(3 points) TF-IDF (compute comment similarity between different ratings)\n","\n","The Amazon rating system is 1 to 5 stars, with 5 stars being the best. The comments with each rating can be viewed as a separate document. In total, we will have 5 separate documents for 1-star, 2-star, 3-star, 4-star, or 5-star comments. Using this document representation to categorize all the comments with different ratings into 5 documents.\n","\n","Each document (1-star, 2 star, 3 star, 4 star, or 5 star comments) can be represented as an N-dimension vector. You need to perform Stopwords removal and Stemming before generating each document. Each dimension in this vector space is defined by the unigrams of all comments from all documents; while the weight for each unigram in this rating can defined by TF-IDF. Specifically, we need to use ”Sub-linear TF scaling” to compute the normalized TF of each unigram in a document\n","\n","(e.g., sklearn.feature extraction.text.TfidfVectorizer(sublinear tf=True)).\n","Construct the vector space representations for these 1 to 5-star reviews and find out the most similar reviews to 1-star, 3-star, and 5-star reviews, where the similarity metric is defined as cosine similarity.\n","\n"],"metadata":{"id":"RLcD_lDQj9F3"}},{"cell_type":"code","source":["# Import google drive\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"yB_Bz8m5ksEM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Read the data"],"metadata":{"id":"Ye63Jc6yvgqm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6gGZIHT0jNVx"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.metrics.pairwise import  linear_kernel"]},{"cell_type":"code","source":["import nltk\n","nltk.download('all')"],"metadata":{"id":"GGUzVIFKA1LW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('/content/gdrive/MyDrive/Text Analytics/HW1/Amazon_Comments.csv',  delimiter=\"^\", header=None, names=[\"No\", \"Title\", \"Date\", \"Bool\", \"Review\", \"Rating\"])\n","df.head()"],"metadata":{"id":"FrX77b3okq4j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data has 2038 rows and 6 columns with no null values"],"metadata":{"id":"o39boYvj8kE7"}},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"A0Vyh_4YZhbO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualization of Ratings Distribution"],"metadata":{"id":"D2XH_cy3g9Ah"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Plot the count of each rating\n","\n","df['Rating'].value_counts().to_frame(\"Count\").plot(kind='bar', figsize=(10, 4), title='Rating Counts', colormap='Accent')\n","plt.title('Rating Counts', fontsize = 15)\n","plt.xlabel('Date', fontsize= 12)\n","plt.ylabel('Count', fontsize = 12)\n","plt.show()"],"metadata":{"id":"huz5-12xiOs_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Cleaning"],"metadata":{"id":"wbgX8MrrZZAn"}},{"cell_type":"code","source":["df1 = df.copy()\n","df1 = df.drop(columns=[\"No\", \"Title\", \"Date\", \"Bool\"])\n","df1.head()"],"metadata":{"id":"ZQXVNrOLe1ex"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Clean the data"],"metadata":{"id":"ZyMcrF1FvmT_"}},{"cell_type":"code","source":["import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from nltk.stem import WordNetLemmatizer\n","import string\n","import re\n","\n","\n","\n","\n","# Function to clean and preprocess text\n","def clean_text(text):\n","\n","    # Remove special characters and numbers\n","    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n","\n","    # Convert text to lowercase\n","    text = text.lower()\n","\n","    # Remove punctuation\n","    text = ''.join([char for char in text if char not in string.punctuation])\n","\n","\n","    # Tokenize text\n","    tokens = nltk.word_tokenize(text)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","\n","    tokens = [word for word in tokens if word not in stop_words and not word.isdigit()]\n","\n","    #Stemming (you can replace with lemmatization if preferred)\n","    #stemmer = PorterStemmer()\n","\n","    #tokens = [stemmer.stem(word) for word in tokens]\n","\n","    # Create a lemmatizer object.\n","    lemmatizer = WordNetLemmatizer()\n","\n","   #Lemmatization\n","    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n","\n","    # Reconstruct cleaned text\n","    cleaned_text = ' '.join(tokens)\n","\n","    return cleaned_text\n"],"metadata":{"id":"nKTNi-JHvfJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Apply the clean_text function to each review in the DataFrame\n","df2 = df1.copy()\n","\n","df2['Clean_Review'] = df1['Review'].apply(clean_text)\n","\n","# Print the cleaned reviews\n","df2.head()"],"metadata":{"id":"6pydpTOBcjFd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Visualize Tokens"],"metadata":{"id":"BfHRA2J8vXD8"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","import nltk\n","from nltk.corpus import stopwords\n","\n","# Download the nltk stopwords if you haven't done so\n","nltk.download('stopwords')\n","\n","# Create a set of stopwords\n","stop_words = set(stopwords.words('english'))\n","\n","# visualize the frequent words\n","text = \" \".join([sentence for sentence in df_incorrect['Clean_text']])\n","\n","# Generate a word cloud with stop words\n","wordcloud = WordCloud(width=800, height=400, stopwords=stop_words, background_color='white').generate(text)\n","\n","# plot the graph\n","plt.figure(figsize=(10,10))\n","plt.imshow(wordcloud, interpolation='bilinear')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"0onP1z_M-48d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import collections\n","from collections import Counter\n","from itertools import chain\n","\n","word_tokenize = nltk.word_tokenize\n","\n","# Tokenize the text column\n","df2['Tokenized_Text'] = df2['Clean_Review'].apply(word_tokenize)\n","\n","# Print the tokenized text\n","corpus = df2['Tokenized_Text']\n","corpus = corpus.tolist()\n","# Flatten list of lists to a single list\n","tokens = list(chain(*corpus))\n","unique_freq = collections.Counter(tokens)\n","# Count each unique element\n","unique_freq_df = pd.DataFrame.from_dict(unique_freq, orient='index').reset_index() # Convert to dataframe\n","# Rename columns\n","unique_freq_df = unique_freq_df.rename(columns={'index': 'Token', 0: 'Count'})\n","# Sort by count\n","unique_freq_df.sort_values('Count', ascending=False, inplace=True)\n","unique_freq_df = unique_freq_df.head(20)\n","\n","unique_freq_df1 = unique_freq_df.reset_index(drop=True)\n","unique_freq_df2 = unique_freq_df1.set_index(\"Token\")\n","unique_freq_df2"],"metadata":{"id":"0TyF6eNpnrju"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xCCfNjrrNJv9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plt.colormaps()\n","unique_freq_df2.plot(kind=\"bar\", figsize= (15,5), grid=False, colormap = \"Spectral_r\")\n","plt.show()"],"metadata":{"id":"NaXG_dA2ohfC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Calculating the TF of each unigram in the document"],"metadata":{"id":"O_1jgtOuzpuE"}},{"cell_type":"code","source":["df3 =df2.copy()\n","df3.head()"],"metadata":{"id":"3a7nBkaL8rCN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 1: Create a TF-IDF Vectorizer with sublinear TF scaling\n","tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True)\n","\n","# Step 2: Fit the Vectorizer to the Text Data\n","tfidf_matrix = tfidf_vectorizer.fit_transform(df3['Clean_Review'])\n","\n","# Step 3: Convert the TF-IDF Matrix to a DataFrame\n","tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n","\n","# Now, tfidf_df contains the TF-IDF vectors with sub-linear TF scaling\n","tfidf = tfidf_df.T\n","\n","tfidf"],"metadata":{"id":"b0NXn9xOzp_4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tf-idf Normalization"],"metadata":{"id":"D1Xp65rTE9ri"}},{"cell_type":"code","source":["# Normalize the above matrix\n","\n","tfidf_norm = tfidf.subtract(tfidf.mean(axis=1), axis = 0)\n","tfidf_norm.head()"],"metadata":{"id":"i1kVlDmYFKUm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cosine Similarity"],"metadata":{"id":"jkztOsgyJAKM"}},{"cell_type":"code","source":["# Calculate Cosine Similarity between all the reviews\n","cosine_similarity_df = pd.DataFrame(cosine_similarity(tfidf_norm, tfidf_norm), index=tfidf.index, columns=tfidf.index)\n","\n","cosine_similarity_df.head()"],"metadata":{"id":"9spbjPGIJAY7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Predict the reviews most similar to 1 star, 3 star and 5 star reviews"],"metadata":{"id":"LrFwLGLGvexX"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","\n","# Separate reviews by star rating\n","one_star_reviews = df3[df3['Rating'] == 1]\n","three_star_reviews = df3[df3['Rating'] == 3]\n","five_star_reviews = df3[df3['Rating'] == 5]\n","\n","# Create a TF-IDF vectorizer\n","tfidf_vectorizer =  TfidfVectorizer(sublinear_tf=True)\n","\n","# Fit and transform the entire text data\n","tfidf_matrix = tfidf_vectorizer.fit_transform(df3['Clean_Review'])\n","\n","# Initialize empty lists to store the most similar reviews and their similarity scores\n","most_similar_one_star = []\n","most_similar_three_star = []\n","most_similar_five_star = []\n","\n","# Calculate cosine similarity for each review with 1-star, 3-star, and 5-star reviews\n","for one_star_review in one_star_reviews['Review']:\n","    similarity_scores = cosine_similarity(tfidf_vectorizer.transform([one_star_review]), tfidf_matrix)\n","    most_similar_idx = similarity_scores.argsort()[0][-2]  # Get the most similar review (excluding itself)\n","    most_similar_one_star.append((df3['Review'].iloc[most_similar_idx], similarity_scores[0][most_similar_idx]))"],"metadata":{"id":"0DlcaNpVvc83"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1 Star Reviews"],"metadata":{"id":"Ogs8H-CKz2f8"}},{"cell_type":"code","source":["# Print the most similar reviews and their similarity scores\n","\n","print(\"Most similar to 1-star review:\")\n","for review, similarity_score in most_similar_one_star:\n","    print(f\"Review: {review}\\nSimilarity Score: {similarity_score}\\n\")"],"metadata":{"id":"NyoYEQrlz1PS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3 Star Reviews"],"metadata":{"id":"ZYcGpBmozl4s"}},{"cell_type":"code","source":["# Three star reviews\n","\n","for three_star_review in three_star_reviews['Review']:\n","    similarity_scores = cosine_similarity(tfidf_vectorizer.transform([three_star_review]), tfidf_matrix)\n","    most_similar_idx = similarity_scores.argsort()[0][-2]\n","    most_similar_three_star.append((df3['Review'].iloc[most_similar_idx], similarity_scores[0][most_similar_idx]))\n","\n","\n","# Print the most similar reviews and their similarity scores\n","\n","print(\"\\nMost similar to 3-star review:\")\n","for review, similarity_score in most_similar_three_star:\n","    print(f\"Review: {review}\\nSimilarity Score: {similarity_score}\\n\")\n"],"metadata":{"id":"taYqW599wrx_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5 Star Reviews"],"metadata":{"id":"tlYMeo0VzplT"}},{"cell_type":"code","source":["\n","for five_star_review in five_star_reviews['Review']:\n","    similarity_scores = cosine_similarity(tfidf_vectorizer.transform([five_star_review]), tfidf_matrix)\n","    most_similar_idx = similarity_scores.argsort()[0][-2]\n","    most_similar_five_star.append((df3['Review'].iloc[most_similar_idx], similarity_scores[0][most_similar_idx]))\n","\n","print(\"\\nMost similar to 5-star review:\")\n","for review, similarity_score in most_similar_five_star:\n","    print(f\"Review: {review}\\nSimilarity Score: {similarity_score}\\n\")"],"metadata":{"id":"E5QaNhH9wzxS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Correct dataset"],"metadata":{"id":"Yk2c_ykeOjrF"}},{"cell_type":"code","source":["# Create the correct dataset\n","df_correct = df[df['flag'] == 1]\n","\n","# remove punctuations\n","df_correct['question'] = df2['text'].str.replace('[^A-Za-z ]+', '')\n","df_correct['question'] = df_correct['question'].str.lower()\n","\n","# create a bag of words\n","df_correct['question_bow'] = df_correct['question'].str.split(' ')\n","df_correct['question_bow']\n","\n","# Apply stopwords\n","df_correct['question_bow'] = df_correct['question_bow'].apply(lambda x: [item for item in x if item not in nltk.corpus.stopwords.words('english')])\n","\n","# create a list of all the words in the bag of words\n","all_words = df_correct['question_bow'].explode().unique()\n","all_words\n","\n","# # count the number of times each word appears\n","word_counts = df_correct['question_bow'].explode().value_counts().to_frame(\"Counts\").reset_index()\n","word_counts\n","\n","\n","# # sort the words by their frequency\n","sorted_word_counts = word_counts.sort_values(by=\"Counts\",ascending=False)\n","sorted_word_counts"],"metadata":{"id":"cXyct80_OiSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the top 30 words that appear most frequently in questions that students tend to do poorly on\n","sorted_30 = sorted_word_counts.drop(index=0).head(30)\n","sorted_30"],"metadata":{"id":"I3mrwbyFOqph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sorted_30.plot(kind='bar', x='index', y='Counts', figsize=(20,5)  )\n","plt.title('Word Frequency of Top 30 words in Correct Data', size = 20)\n","plt.xlabel('Words', size = 15)\n","plt.ylabel('Frequency', size = 15)\n","plt.xticks(size = 12)\n","plt.yticks(size = 12)\n","plt.show()"],"metadata":{"id":"vYsqXDYgOuVh"},"execution_count":null,"outputs":[]}]}